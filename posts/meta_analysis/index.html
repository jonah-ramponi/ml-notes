<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Why did Meta publish the Llama models for free? | Jonah&#39;s ML Notes</title>
<meta name="keywords" content="">
<meta name="description" content="My thoughts on Meta&#39;s strategic decision to open source the llama model weights.">
<meta name="author" content="">
<link rel="canonical" href="https://www.jonahramponi.com/posts/meta_analysis/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://www.jonahramponi.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://www.jonahramponi.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://www.jonahramponi.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://www.jonahramponi.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://www.jonahramponi.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://www.jonahramponi.com/posts/meta_analysis/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"
    integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js"
    integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY"
    crossorigin="anonymous"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js"
    integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>


<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false }
            ]
        });
    });
</script>


<meta property="og:title" content="Why did Meta publish the Llama models for free?" />
<meta property="og:description" content="My thoughts on Meta&#39;s strategic decision to open source the llama model weights." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.jonahramponi.com/posts/meta_analysis/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-08-23T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-08-23T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Why did Meta publish the Llama models for free?"/>
<meta name="twitter:description" content="My thoughts on Meta&#39;s strategic decision to open source the llama model weights."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://www.jonahramponi.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Why did Meta publish the Llama models for free?",
      "item": "https://www.jonahramponi.com/posts/meta_analysis/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Why did Meta publish the Llama models for free?",
  "name": "Why did Meta publish the Llama models for free?",
  "description": "My thoughts on Meta's strategic decision to open source the llama model weights.",
  "keywords": [
    
  ],
  "articleBody": "To understand why Meta has open sourced the Llama family of models, it is important to understand how Meta makes money. Meta makes money from adverts. Almost their entire revenue comes from adverts (1). So,\nwhy have Meta invested so much money into the Llama models?\nProbably, to make more money from adverts.\nHere are some ways in which the open source release of the Llama models might help Meta make more money from adverts.\nTo increase the value of their data Open sourcing the Llama model weights has led to massive adoption of the Llama models by developers and researchers. This community-driven effort has greatly advanced understanding of generative AI models. These advancements should enable Meta to extract more value from their data.\nA while back, a leaked memo from a Google Researcher titled “We Have No Moat, And Neither Does OpenAI“ was released (2). Meta promptly decided to focus on building bridges with the open source community. They do, however, keep a deep moat filled with crocodiles around what is truly valuable to them - their data.\nIt would not surprise me if we never hear about the models trained on our Instagram and Facebook data. I think it will be these models which will reap the biggest rewards for Meta - because those models might have the potential to increase advertising revenues by a percentage or two, and that is worth a lot to Meta.\nSo what exactly might this value add look like?\nI don’t know. That’s a question for the researchers at Meta under super strict NDAs. But maybe:\nImprovements to multimodal models which could allow them to extract more information from user’s posts. For instance, they could better identify the types, values, styles, etc., of the clothes an individual wears. They might better understand the look they go for. This would enhance targeted advertising.\nImprovements to language models may allow for better analysis of the tone and sentiment in posts. Meta could then tailor ads to match the user’s current emotional state, improving engagement and relevance. For instance, if emotional stress were detected Meta could recommend using Facebook less.\nBut why didn’t Meta just train the Llama models privately and keep them for internal use? Why expose themselves to potential legal issues or lawsuits by making them open source?\nI believe the prevailing theory is that Meta is strategically commoditizing its complements (3). They have a core revenue stream—advertising—and by making certain technologies widely available, they indirectly enhance their primary money-making activity.\nI would guess that Meta intends to commoditize as much of their tech stack as possible. For instance, by creating a new frontend framework which makes it easier to build scalable social network sites. Or by creating a better framework than tensorflow for building digital advertising ML models.\nMeta can initial development this to serve what they need internally, providing top quality engineering for the initial codebase. Once released to the open-source community, developers around the world contribute to refining and expanding its functionality.\nWhen a company like Meta finds itself behind the competition in certain areas, open-sourcing its work will help bridge the gap. This approach ensures that Meta catches up thanks to continual improvements by the community. These developments feed back into Meta’s ultimate goal—better advertising revenues\nTo recruit Open-sourcing the Llama models exposes thousands of developers to Meta’s technology. New hires, particularly researchers, may already be familiar with Meta’s tools and models, reducing the need for extensive training.\nFurthermore, by publishing models for free, Meta will attract researchers and developers who want to work on cutting-edge AI technologies. It might not be quite as good an advert as The Internship was for Google, but I believe that the decision to open source the Llama models has improved Meta’s reputation amongst much of the community. And that is worth something.\nBecause big tech is a battlefield In 1812, during Napoleon Bonaparte’s invasion of Russia, the Russian army employed a ruthless strategy as they retreated: they burned crops, villages, and resources to deny the advancing French any supplies. This “Scorched Earth” tactic is a military strategy where anything that could aid the enemy is destroyed.\nWith Generative AI, Meta is doing the opposite. Let’s compare AI to whoopee cushions.\nImagine a world in which one company has a strategy to produce the best whoopee cushions (Microsoft). Initially, they have seemingly total dominance. Nobody is safe.\nTo counter Microsoft’s dominance, Meta takes whoopee cushions and gives them to everyone. They teach everyone how to make them. Microsoft is now far less big and scary to Meta. Their threats of price increases on the Big Whooper 3000 model can no longer be justified. The power is no longer concentrated in Microsoft’s hands as everyone now has open access to whoopee cushions.\nHowever, this strategy isn’t as simple as it seems. While it might appear that Meta is levelling the playing field, not everyone can leverage these whoopee cushions effectively. Small players should benefit, but large enterprises might still prefer Microsoft’s integrated solutions, even at a higher cost. Microsoft’s dominance isn’t just about the whoopee cushions themselves; it’s about the entire flatulent ecosystem they control.\nWhether the world is a better place in this example is up for debate.\nI’m sure many people would rather live in a world with no whoopee cushions at all.\nBig tech is full of battlefield-like tactics. Another example is Alphabet’s dominance in the smartphone market. For a while Facebook considered developing phones. To make these phones, Facebook wanted their own operating system and their own devices, and needed navigation software for it. So, So, Facebook tried to buy Waze (a similar service to Google Maps).\nThere were many other reasons Facebook wanted Waze; one key reason being to deliver better location-based mobile advertising and optimise local search results. However, right before they could buy Waze for 500 million dollars, Google stepped in and paid nearly a billion dollars to snatch it up.\nWhy? I think that Google probably bought Waze so that Facebook would not have it. They probably didn’t really need Waze, but it contributed to Facebook abandoning their smartphone plans. It stunted Facebook’s expansion. For big tech, messing up each other’s game is a key, legitimate business strategy.\nSimilarly, Microsoft’s (and OpenAI’s) dominance in Generative AI may have been enough of a threat to prompt Meta into action. By making AI tools freely available, Meta isn’t simply playing nice—it’s playing smart. It’s a calculated move to dilute Microsoft’s power and shift the balance in the game, ensuring that no one company holds too much sway in the AI landscape.\nSo, while Meta’s actions might seem altruistic on the surface, they are driven by the same competitive instincts that have shaped big tech for years.\nWhether this leads to a better world, with more innovation and access, or just a noisier one full of whoopee cushions, remains to be seen.\n(1) In the second quarter of 2024, 98.1% of Meta’s revenue came from adverts. Meta Q2 Earnings\n(2) We Have No Moat, And Neither Does OpenAI\n(3) Joel on Software discusses Commoditizing your Complement\n",
  "wordCount" : "1187",
  "inLanguage": "en",
  "datePublished": "2024-08-23T00:00:00Z",
  "dateModified": "2024-08-23T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://www.jonahramponi.com/posts/meta_analysis/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Jonah's ML Notes",
    "logo": {
      "@type": "ImageObject",
      "url": "https://www.jonahramponi.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://www.jonahramponi.com/" accesskey="h" title="Jonah&#39;s ML Notes (Alt + H)">Jonah&#39;s ML Notes</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://www.jonahramponi.com/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://www.jonahramponi.com/about" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Why did Meta publish the Llama models for free?
    </h1>
    <div class="post-description">
      My thoughts on Meta&#39;s strategic decision to open source the llama model weights.
    </div>
    <div class="post-meta"><span title='2024-08-23 00:00:00 +0000 UTC'>August 23, 2024</span>

</div>
  </header> 
  <div class="post-content"><p>To understand why Meta has open sourced the Llama family of models, it is important to understand how Meta makes money. Meta makes money from adverts. Almost their entire revenue comes from adverts (1). So,</p>
<p>why have Meta invested so much money into the Llama models?</p>
<p><em>Probably, to make more money from adverts.</em></p>
<p>Here are some ways in which the open source release of the Llama models might help Meta make more money from adverts.</p>
<h3 id="to-increase-the-value-of-their-data">To increase the value of their data<a hidden class="anchor" aria-hidden="true" href="#to-increase-the-value-of-their-data">#</a></h3>
<p>Open sourcing the Llama model weights has led to massive adoption of the Llama models by developers and researchers. This community-driven effort has greatly advanced understanding of generative AI models. These advancements should enable Meta to extract more value from their data.</p>
<p>A while back, a leaked memo from a Google Researcher titled <em>“We Have No Moat, And Neither Does OpenAI“</em> was released (2). Meta promptly decided to focus on building bridges with the open source community. They do, however, keep a deep moat filled with crocodiles around what is truly valuable to them - their data.</p>
<p>It would not surprise me if we never hear about the models trained on our Instagram and Facebook data. I think it will be these models which will reap the biggest rewards for Meta - because those models might have the potential to increase advertising revenues by a percentage or two, and that is worth a lot to Meta.</p>
<p>So what exactly might this value add look like?</p>
<p>I don’t know. That’s a question for the researchers at Meta under super strict NDAs. But maybe:</p>
<ol>
<li>
<p>Improvements to multimodal models which could allow them to extract more information from user’s posts. For instance, they could better identify the types, values, styles, etc., of the clothes an individual wears. They might better understand the look they go for. This would enhance targeted advertising.</p>
</li>
<li>
<p>Improvements to language models may allow for better analysis of the tone and sentiment in posts. Meta could then tailor ads to match the user’s current emotional state, improving engagement and relevance. For instance, if emotional stress were detected Meta could recommend <em>using Facebook less</em>.</p>
</li>
</ol>
<p>But why didn’t Meta just train the Llama models privately and keep them for internal use? Why expose themselves to potential legal issues or lawsuits by making them open source?</p>
<p>I believe the prevailing theory is that Meta is strategically commoditizing its complements (3). They have a core revenue stream—advertising—and by making certain technologies widely available, they indirectly enhance their primary money-making activity.</p>
<p>I would guess that Meta intends to commoditize as much of their tech stack as possible. For instance, by creating a new frontend framework which makes it easier to build scalable social network sites. Or by creating a better framework than tensorflow for building digital advertising ML models.</p>
<p>Meta can initial development this to serve what they need internally, providing top quality engineering for the initial codebase. Once released to the open-source community, developers around the world contribute to refining and expanding its functionality.</p>
<p>When a company like Meta finds itself behind the competition in certain areas, open-sourcing its work will help bridge the gap. This approach ensures that Meta catches up thanks to continual improvements by the community. These developments feed back into Meta’s ultimate goal—better advertising revenues</p>
<h3 id="to-recruit">To recruit<a hidden class="anchor" aria-hidden="true" href="#to-recruit">#</a></h3>
<p>Open-sourcing the Llama models exposes thousands of developers to Meta’s technology. New hires, particularly researchers, may already be familiar with Meta’s tools and models, reducing the need for extensive training.</p>
<p>Furthermore, by publishing models for free, Meta will attract researchers and developers who want to work on cutting-edge AI technologies. It might not be quite as good an advert as <em>The Internship</em> was for Google, but I believe that the decision to open source the Llama models has improved Meta’s reputation amongst much of the community. And that is worth something.</p>
<h3 id="because-big-tech-is-a-battlefield">Because big tech is a battlefield<a hidden class="anchor" aria-hidden="true" href="#because-big-tech-is-a-battlefield">#</a></h3>
<p>In 1812, during Napoleon Bonaparte’s invasion of Russia, the Russian army employed a ruthless strategy as they retreated: they burned crops, villages, and resources to deny the advancing French any supplies. This <em>&ldquo;Scorched Earth&rdquo;</em> tactic is a military strategy where anything that could aid the enemy is destroyed.</p>
<p>With Generative AI, Meta is doing the opposite. Let’s compare AI to whoopee cushions.</p>
<p>Imagine a world in which one company has a strategy to produce the best whoopee cushions (Microsoft). Initially, they have seemingly total dominance. Nobody is safe.</p>
<p>To counter Microsoft’s dominance, Meta takes whoopee cushions and gives them to everyone. They teach everyone how to make them. Microsoft is now far less big and scary to Meta. Their threats of price increases on the Big Whooper 3000 model can no longer be justified. The power is no longer concentrated in Microsoft&rsquo;s hands as everyone now has open access to whoopee cushions.</p>
<p>However, this strategy isn&rsquo;t as simple as it seems. While it might appear that Meta is levelling the playing field, not everyone can leverage these whoopee cushions effectively. Small players should benefit, but large enterprises might still prefer Microsoft&rsquo;s integrated solutions, even at a higher cost. Microsoft&rsquo;s dominance isn&rsquo;t just about the whoopee cushions themselves; it&rsquo;s about the entire flatulent ecosystem they control.</p>
<p>Whether the world is a better place in this example is up for debate.</p>
<p>I’m sure many people would rather live in a world with no whoopee cushions at all.</p>
<p>Big tech is full of battlefield-like tactics. Another example is Alphabet’s dominance in the smartphone market. For a while Facebook considered developing phones. To make these phones, Facebook wanted their own operating system and their own devices, and needed navigation software for it. So, So, Facebook tried to buy Waze (a similar service to Google Maps).</p>
<p>There were many other reasons Facebook wanted Waze; one key reason being to deliver better location-based mobile advertising and optimise local search results. However, right before they could buy Waze for 500 million dollars, Google stepped in and paid nearly a billion dollars to snatch it up.</p>
<p>Why? I think that Google probably bought Waze so that Facebook would not have it. They probably didn&rsquo;t really need Waze, but it contributed to Facebook abandoning their smartphone plans. It stunted Facebook&rsquo;s expansion. For big tech, messing up each other&rsquo;s game is a key, legitimate business strategy.</p>
<p>Similarly, Microsoft&rsquo;s (and OpenAI’s) dominance in Generative AI may have been enough of a threat to prompt Meta into action. By making AI tools freely available, Meta isn&rsquo;t simply playing nice—it’s playing smart. It’s a calculated move to dilute Microsoft’s power and shift the balance in the game, ensuring that no one company holds too much sway in the AI landscape.</p>
<p>So, while Meta’s actions might seem altruistic on the surface, they are driven by the same competitive instincts that have shaped big tech for years.</p>
<p>Whether this leads to a better world, with more innovation and access, or just a noisier one full of whoopee cushions, remains to be seen.</p>
<p>(1) In the second quarter of 2024, 98.1% of Meta’s revenue came from adverts. <a href="ps://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-Second-Quarter-2024-Results/default.aspx">Meta Q2 Earnings</a></p>
<p>(2) <a href="https://www.semianalysis.com/p/google-we-have-no-moat-and-neither">We Have No Moat, And Neither Does OpenAI</a></p>
<p>(3) <a href="https://www.joelonsoftware.com/2002/06/12/strategy-letter-v/">Joel on Software discusses Commoditizing your Complement</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://www.jonahramponi.com/">Jonah&#39;s ML Notes</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
